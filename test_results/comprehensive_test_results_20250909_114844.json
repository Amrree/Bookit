{
  "timestamp": "2025-09-09T11:47:43.250816",
  "test_suites": [
    {
      "name": "Core Functionality",
      "file": "tests/test_core_functionality.py",
      "category": "unit",
      "status": "FAILED",
      "duration": 6.045931100845337,
      "passed": 32,
      "failed": 2,
      "skipped": 0,
      "errors": 0,
      "total": 34,
      "returncode": 1,
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.13.3, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /workspace\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, asyncio-1.1.0, mock-3.15.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 34 items\n\ntests/test_core_functionality.py::TestCoreImports::test_memory_manager_import PASSED [  2%]\ntests/test_core_functionality.py::TestCoreImports::test_llm_client_import PASSED [  5%]\ntests/test_core_functionality.py::TestCoreImports::test_tool_manager_import PASSED [  8%]\ntests/test_core_functionality.py::TestCoreImports::test_agent_manager_import PASSED [ 11%]\ntests/test_core_functionality.py::TestCoreImports::test_agents_import PASSED [ 14%]\ntests/test_core_functionality.py::TestCoreImports::test_document_ingestor_import PASSED [ 17%]\ntests/test_core_functionality.py::TestCoreImports::test_book_workflow_import PASSED [ 20%]\ntests/test_core_functionality.py::TestCoreImports::test_cli_import PASSED [ 23%]\ntests/test_core_functionality.py::TestCoreImports::test_gui_import FAILED [ 26%]\ntests/test_core_functionality.py::TestMemoryManagerCore::test_memory_manager_creation PASSED [ 29%]\ntests/test_core_functionality.py::TestMemoryManagerCore::test_memory_entry_creation PASSED [ 32%]\ntests/test_core_functionality.py::TestMemoryManagerCore::test_retrieval_result_creation PASSED [ 35%]\ntests/test_core_functionality.py::TestLLMClientCore::test_llm_client_creation PASSED [ 38%]\ntests/test_core_functionality.py::TestLLMClientCore::test_llm_client_attributes PASSED [ 41%]\ntests/test_core_functionality.py::TestToolManagerCore::test_tool_manager_creation PASSED [ 44%]\ntests/test_core_functionality.py::TestToolManagerCore::test_tool_definition_creation PASSED [ 47%]\ntests/test_core_functionality.py::TestToolManagerCore::test_tool_request_creation PASSED [ 50%]\ntests/test_core_functionality.py::TestAgentManagerCore::test_agent_manager_creation PASSED [ 52%]\ntests/test_core_functionality.py::TestAgentManagerCore::test_agent_status_enum PASSED [ 55%]\ntests/test_core_functionality.py::TestAgentManagerCore::test_task_status_enum PASSED [ 58%]\ntests/test_core_functionality.py::TestDocumentIngestorCore::test_document_ingestor_creation PASSED [ 61%]\ntests/test_core_functionality.py::TestDocumentIngestorCore::test_supported_formats PASSED [ 64%]\ntests/test_core_functionality.py::TestBookWorkflowCore::test_book_workflow_creation PASSED [ 67%]\ntests/test_core_functionality.py::TestCLICore::test_cli_module_structure PASSED [ 70%]\ntests/test_core_functionality.py::TestCLICore::test_cli_commands_available PASSED [ 73%]\ntests/test_core_functionality.py::TestGUICore::test_gui_module_structure FAILED [ 76%]\ntests/test_core_functionality.py::TestIntegrationCore::test_module_interconnections PASSED [ 79%]\ntests/test_core_functionality.py::TestIntegrationCore::test_data_flow_compatibility PASSED [ 82%]\ntests/test_core_functionality.py::TestErrorHandling::test_memory_manager_error_handling PASSED [ 85%]\ntests/test_core_functionality.py::TestErrorHandling::test_llm_client_error_handling PASSED [ 88%]\ntests/test_core_functionality.py::TestErrorHandling::test_tool_manager_error_handling PASSED [ 91%]\ntests/test_core_functionality.py::TestPerformance::test_memory_manager_performance PASSED [ 94%]\ntests/test_core_functionality.py::TestPerformance::test_llm_client_performance PASSED [ 97%]\ntests/test_core_functionality.py::TestPerformance::test_tool_manager_performance PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________________ TestCoreImports.test_gui_import ________________________\ntests/test_core_functionality.py:72: in test_gui_import\n    import gui\ngui.py:23: in <module>\n    from PyQt6.QtWidgets import (\nE   ImportError: libEGL.so.1: cannot open shared object file: No such file or directory\n____________________ TestGUICore.test_gui_module_structure _____________________\ntests/test_core_functionality.py:306: in test_gui_module_structure\n    import gui\ngui.py:23: in <module>\n    from PyQt6.QtWidgets import (\nE   ImportError: libEGL.so.1: cannot open shared object file: No such file or directory\n=============================== warnings summary ===============================\n../home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21\n  /home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============================= slowest 10 durations =============================\n0.44s call     tests/test_core_functionality.py::TestMemoryManagerCore::test_memory_manager_creation\n0.35s call     tests/test_core_functionality.py::TestErrorHandling::test_memory_manager_error_handling\n0.28s call     tests/test_core_functionality.py::TestIntegrationCore::test_module_interconnections\n0.28s call     tests/test_core_functionality.py::TestPerformance::test_memory_manager_performance\n0.00s call     tests/test_core_functionality.py::TestCoreImports::test_gui_import\n0.00s call     tests/test_core_functionality.py::TestGUICore::test_gui_module_structure\n0.00s call     tests/test_core_functionality.py::TestCoreImports::test_cli_import\n0.00s call     tests/test_core_functionality.py::TestLLMClientCore::test_llm_client_creation\n0.00s call     tests/test_core_functionality.py::TestErrorHandling::test_llm_client_error_handling\n0.00s call     tests/test_core_functionality.py::TestLLMClientCore::test_llm_client_attributes\n=========================== short test summary info ============================\nFAILED tests/test_core_functionality.py::TestCoreImports::test_gui_import - ImportError: libEGL.so.1: cannot open shared object file: No such file or directory\nFAILED tests/test_core_functionality.py::TestGUICore::test_gui_module_structure - ImportError: libEGL.so.1: cannot open shared object file: No such file or directory\n=================== 2 failed, 32 passed, 1 warning in 1.42s ====================\n",
      "stderr": ""
    },
    {
      "name": "Memory Operations",
      "file": "tests/test_memory_operations.py",
      "category": "unit",
      "status": "PASSED",
      "duration": 7.032652378082275,
      "passed": 29,
      "failed": 0,
      "skipped": 0,
      "errors": 0,
      "total": 29,
      "returncode": 0,
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.13.3, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /workspace\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, asyncio-1.1.0, mock-3.15.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 29 items\n\ntests/test_memory_operations.py::TestMemoryOperations::test_memory_manager_initialization PASSED [  3%]\ntests/test_memory_operations.py::TestMemoryOperations::test_memory_manager_stats PASSED [  6%]\ntests/test_memory_operations.py::TestMemoryOperations::test_memory_clear_operation PASSED [ 10%]\ntests/test_memory_operations.py::TestMemoryOperations::test_memory_entry_validation PASSED [ 13%]\ntests/test_memory_operations.py::TestMemoryOperations::test_retrieval_result_validation PASSED [ 17%]\ntests/test_memory_operations.py::TestLLMOperations::test_llm_client_initialization PASSED [ 20%]\ntests/test_memory_operations.py::TestLLMOperations::test_llm_client_providers PASSED [ 24%]\ntests/test_memory_operations.py::TestLLMOperations::test_llm_generate_with_mock PASSED [ 27%]\ntests/test_memory_operations.py::TestToolOperations::test_tool_manager_initialization PASSED [ 31%]\ntests/test_memory_operations.py::TestToolOperations::test_tool_manager_stats PASSED [ 34%]\ntests/test_memory_operations.py::TestToolOperations::test_tool_definition_validation PASSED [ 37%]\ntests/test_memory_operations.py::TestToolOperations::test_tool_request_validation PASSED [ 41%]\ntests/test_memory_operations.py::TestToolOperations::test_tool_response_validation PASSED [ 44%]\ntests/test_memory_operations.py::TestAgentOperations::test_agent_manager_initialization PASSED [ 48%]\ntests/test_memory_operations.py::TestAgentOperations::test_agent_status_enum_values PASSED [ 51%]\ntests/test_memory_operations.py::TestAgentOperations::test_task_status_enum_values PASSED [ 55%]\ntests/test_memory_operations.py::TestAgentOperations::test_agent_task_validation PASSED [ 58%]\ntests/test_memory_operations.py::TestDocumentOperations::test_document_ingestor_initialization PASSED [ 62%]\ntests/test_memory_operations.py::TestDocumentOperations::test_supported_formats PASSED [ 65%]\ntests/test_memory_operations.py::TestBookWorkflowOperations::test_book_metadata_creation PASSED [ 68%]\ntests/test_memory_operations.py::TestBookWorkflowOperations::test_chapter_metadata_creation PASSED [ 72%]\ntests/test_memory_operations.py::TestIntegrationOperations::test_memory_tool_integration PASSED [ 75%]\ntests/test_memory_operations.py::TestIntegrationOperations::test_agent_memory_integration PASSED [ 79%]\ntests/test_memory_operations.py::TestErrorHandling::test_memory_error_handling PASSED [ 82%]\ntests/test_memory_operations.py::TestErrorHandling::test_tool_error_handling PASSED [ 86%]\ntests/test_memory_operations.py::TestErrorHandling::test_llm_error_handling PASSED [ 89%]\ntests/test_memory_operations.py::TestPerformance::test_memory_initialization_performance PASSED [ 93%]\ntests/test_memory_operations.py::TestPerformance::test_tool_initialization_performance PASSED [ 96%]\ntests/test_memory_operations.py::TestPerformance::test_agent_initialization_performance PASSED [100%]\n\n=============================== warnings summary ===============================\n../home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21\n  /home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============================= slowest 10 durations =============================\n0.42s call     tests/test_memory_operations.py::TestMemoryOperations::test_memory_manager_initialization\n0.31s call     tests/test_memory_operations.py::TestMemoryOperations::test_memory_clear_operation\n0.31s call     tests/test_memory_operations.py::TestPerformance::test_memory_initialization_performance\n0.30s call     tests/test_memory_operations.py::TestIntegrationOperations::test_agent_memory_integration\n0.29s call     tests/test_memory_operations.py::TestMemoryOperations::test_memory_manager_stats\n0.29s call     tests/test_memory_operations.py::TestErrorHandling::test_memory_error_handling\n0.29s call     tests/test_memory_operations.py::TestIntegrationOperations::test_memory_tool_integration\n0.00s call     tests/test_memory_operations.py::TestLLMOperations::test_llm_generate_with_mock\n0.00s call     tests/test_memory_operations.py::TestLLMOperations::test_llm_client_initialization\n0.00s call     tests/test_memory_operations.py::TestErrorHandling::test_llm_error_handling\n======================== 29 passed, 1 warning in 2.24s =========================\n",
      "stderr": ""
    },
    {
      "name": "Simple Tests",
      "file": "tests/test_simple.py",
      "category": "unit",
      "status": "FAILED",
      "duration": 4.887094259262085,
      "passed": 9,
      "failed": 1,
      "skipped": 0,
      "errors": 0,
      "total": 10,
      "returncode": 1,
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.13.3, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /workspace\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, asyncio-1.1.0, mock-3.15.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 10 items\n\ntests/test_simple.py::TestSimple::test_basic_imports PASSED              [ 10%]\ntests/test_simple.py::TestSimple::test_memory_manager_creation PASSED    [ 20%]\ntests/test_simple.py::TestSimple::test_llm_client_creation PASSED        [ 30%]\ntests/test_simple.py::TestSimple::test_tool_manager_creation PASSED      [ 40%]\ntests/test_simple.py::TestSimple::test_agent_imports PASSED              [ 50%]\ntests/test_simple.py::TestSimple::test_book_workflow_import PASSED       [ 60%]\ntests/test_simple.py::TestSimple::test_document_ingestor_import PASSED   [ 70%]\ntests/test_simple.py::TestSimple::test_cli_import PASSED                 [ 80%]\ntests/test_simple.py::TestSimple::test_gui_import FAILED                 [ 90%]\ntests/test_simple.py::TestSimple::test_basic_functionality PASSED        [100%]\n\n=================================== FAILURES ===================================\n__________________________ TestSimple.test_gui_import __________________________\ntests/test_simple.py:92: in test_gui_import\n    import gui\ngui.py:23: in <module>\n    from PyQt6.QtWidgets import (\nE   ImportError: libEGL.so.1: cannot open shared object file: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\ntests/test_simple.py:99: in test_gui_import\n    pytest.fail(f\"Failed to import gui: {e}\")\nE   Failed: Failed to import gui: libEGL.so.1: cannot open shared object file: No such file or directory\n=============================== warnings summary ===============================\n../home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21\n  /home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============================= slowest 10 durations =============================\n0.48s call     tests/test_simple.py::TestSimple::test_memory_manager_creation\n0.00s call     tests/test_simple.py::TestSimple::test_gui_import\n0.00s call     tests/test_simple.py::TestSimple::test_llm_client_creation\n0.00s call     tests/test_simple.py::TestSimple::test_cli_import\n0.00s call     tests/test_simple.py::TestSimple::test_tool_manager_creation\n0.00s setup    tests/test_simple.py::TestSimple::test_basic_imports\n0.00s teardown tests/test_simple.py::TestSimple::test_gui_import\n0.00s call     tests/test_simple.py::TestSimple::test_basic_imports\n0.00s call     tests/test_simple.py::TestSimple::test_basic_functionality\n0.00s setup    tests/test_simple.py::TestSimple::test_llm_client_creation\n=========================== short test summary info ============================\nFAILED tests/test_simple.py::TestSimple::test_gui_import - Failed: Failed to import gui: libEGL.so.1: cannot open shared object file: No such file or directory\n==================== 1 failed, 9 passed, 1 warning in 0.52s ====================\n",
      "stderr": ""
    },
    {
      "name": "GUI Comprehensive",
      "file": "tests/test_gui_comprehensive.py",
      "category": "integration",
      "status": "FAILED",
      "duration": 4.401704549789429,
      "passed": 0,
      "failed": 0,
      "skipped": 0,
      "errors": 0,
      "total": 0,
      "returncode": 2,
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.13.3, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /workspace\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, asyncio-1.1.0, mock-3.15.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 0 items / 1 error\n\n==================================== ERRORS ====================================\n_______________ ERROR collecting tests/test_gui_comprehensive.py _______________\nImportError while importing test module '/workspace/tests/test_gui_comprehensive.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/python.py:498: in importtestmodule\n    mod = import_path(\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n/usr/lib/python3.13/importlib/__init__.py:88: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/assertion/rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests/test_gui_comprehensive.py:9: in <module>\n    from PyQt6.QtWidgets import QApplication\nE   ImportError: libEGL.so.1: cannot open shared object file: No such file or directory\n=============================== warnings summary ===============================\n../home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21\n  /home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nERROR tests/test_gui_comprehensive.py\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n========================= 1 warning, 1 error in 0.13s ==========================\n",
      "stderr": ""
    },
    {
      "name": "Document Ingestor Comprehensive",
      "file": "tests/test_document_ingestor_comprehensive.py",
      "category": "unit",
      "status": "FAILED",
      "duration": 5.334714889526367,
      "passed": 2,
      "failed": 33,
      "skipped": 0,
      "errors": 0,
      "total": 35,
      "returncode": 1,
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.13.3, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /workspace\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, asyncio-1.1.0, mock-3.15.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 35 items\n\ntests/test_document_ingestor_comprehensive.py::TestDocumentIngestorCore::test_ingestor_initialization PASSED [  2%]\ntests/test_document_ingestor_comprehensive.py::TestDocumentIngestorCore::test_supported_formats PASSED [  5%]\ntests/test_document_ingestor_comprehensive.py::TestDocumentIngestorCore::test_format_detection FAILED [  8%]\ntests/test_document_ingestor_comprehensive.py::TestDocumentIngestorCore::test_unsupported_format FAILED [ 11%]\ntests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_metadata_extraction FAILED [ 14%]\ntests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_text_extraction FAILED [ 17%]\ntests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_multiple_pages FAILED [ 20%]\ntests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_error_handling FAILED [ 22%]\ntests/test_document_ingestor_comprehensive.py::TestTXTProcessing::test_txt_metadata_extraction FAILED [ 25%]\ntests/test_document_ingestor_comprehensive.py::TestTXTProcessing::test_txt_text_extraction FAILED [ 28%]\ntests/test_document_ingestor_comprehensive.py::TestTXTProcessing::test_txt_encoding_handling FAILED [ 31%]\ntests/test_document_ingestor_comprehensive.py::TestMarkdownProcessing::test_md_metadata_extraction FAILED [ 34%]\ntests/test_document_ingestor_comprehensive.py::TestMarkdownProcessing::test_md_text_extraction FAILED [ 37%]\ntests/test_document_ingestor_comprehensive.py::TestMarkdownProcessing::test_md_frontmatter_handling FAILED [ 40%]\ntests/test_document_ingestor_comprehensive.py::TestDOCXProcessing::test_docx_metadata_extraction FAILED [ 42%]\ntests/test_document_ingestor_comprehensive.py::TestDOCXProcessing::test_docx_text_extraction FAILED [ 45%]\ntests/test_document_ingestor_comprehensive.py::TestDOCXProcessing::test_docx_error_handling FAILED [ 48%]\ntests/test_document_ingestor_comprehensive.py::TestEPUBProcessing::test_epub_metadata_extraction FAILED [ 51%]\ntests/test_document_ingestor_comprehensive.py::TestEPUBProcessing::test_epub_text_extraction FAILED [ 54%]\ntests/test_document_ingestor_comprehensive.py::TestDocumentMetadata::test_metadata_creation FAILED [ 57%]\ntests/test_document_ingestor_comprehensive.py::TestDocumentMetadata::test_metadata_validation FAILED [ 60%]\ntests/test_document_ingestor_comprehensive.py::TestDocumentIngestion::test_pdf_ingestion FAILED [ 62%]\ntests/test_document_ingestor_comprehensive.py::TestDocumentIngestion::test_txt_ingestion FAILED [ 65%]\ntests/test_document_ingestor_comprehensive.py::TestDocumentIngestion::test_md_ingestion FAILED [ 68%]\ntests/test_document_ingestor_comprehensive.py::TestDocumentIngestion::test_docx_ingestion FAILED [ 71%]\ntests/test_document_ingestor_comprehensive.py::TestDocumentIngestion::test_epub_ingestion FAILED [ 74%]\ntests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_nonexistent_file FAILED [ 77%]\ntests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_corrupted_pdf FAILED [ 80%]\ntests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_corrupted_docx FAILED [ 82%]\ntests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_permission_error FAILED [ 85%]\ntests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_encoding_error FAILED [ 88%]\ntests/test_document_ingestor_comprehensive.py::TestPerformance::test_large_file_handling FAILED [ 91%]\ntests/test_document_ingestor_comprehensive.py::TestPerformance::test_ingestion_performance FAILED [ 94%]\ntests/test_document_ingestor_comprehensive.py::TestIntegration::test_memory_manager_integration FAILED [ 97%]\ntests/test_document_ingestor_comprehensive.py::TestIntegration::test_agent_integration FAILED [100%]\n\n=================================== FAILURES ===================================\n________________ TestDocumentIngestorCore.test_format_detection ________________\ntests/test_document_ingestor_comprehensive.py:41: in test_format_detection\n    assert ingestor._detect_format('test.pdf') == '.pdf'\n           ^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'DocumentIngestor' object has no attribute '_detect_format'\n_______________ TestDocumentIngestorCore.test_unsupported_format _______________\ntests/test_document_ingestor_comprehensive.py:62: in test_unsupported_format\n    with pytest.raises(ValueError, match=\"Unsupported file format\"):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   Failed: DID NOT RAISE <class 'ValueError'>\n________________ TestPDFProcessing.test_pdf_metadata_extraction ________________\ntests/test_document_ingestor_comprehensive.py:92: in test_pdf_metadata_extraction\n    metadata = ingestor._extract_pdf_metadata('test.pdf')\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: DocumentIngestor._extract_pdf_metadata() missing 1 required positional argument: 'metadata'\n__________________ TestPDFProcessing.test_pdf_text_extraction __________________\ntests/test_document_ingestor_comprehensive.py:111: in test_pdf_text_extraction\n    assert text == mock_text\nE   AssertionError: assert <coroutine object DocumentIngestor._extract_pdf_text at 0x7f27f8f46240> == 'This is test content from PDF document.'\n__________________ TestPDFProcessing.test_pdf_multiple_pages ___________________\ntests/test_document_ingestor_comprehensive.py:129: in test_pdf_multiple_pages\n    assert \"Page 1 content\" in text\n           ^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: argument of type 'coroutine' is not iterable\n__________________ TestPDFProcessing.test_pdf_error_handling ___________________\ntests/test_document_ingestor_comprehensive.py:138: in test_pdf_error_handling\n    with pytest.raises(Exception, match=\"PDF read error\"):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   Failed: DID NOT RAISE <class 'Exception'>\n________________ TestTXTProcessing.test_txt_metadata_extraction ________________\ntests/test_document_ingestor_comprehensive.py:155: in test_txt_metadata_extraction\n    metadata = ingestor._extract_txt_metadata('test.txt')\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'DocumentIngestor' object has no attribute '_extract_txt_metadata'. Did you mean: '_extract_pdf_metadata'?\n__________________ TestTXTProcessing.test_txt_text_extraction __________________\ntests/test_document_ingestor_comprehensive.py:165: in test_txt_text_extraction\n    text = ingestor._extract_txt_text('test.txt')\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'DocumentIngestor' object has no attribute '_extract_txt_text'. Did you mean: '_extract_pdf_text'?\n_________________ TestTXTProcessing.test_txt_encoding_handling _________________\ntests/test_document_ingestor_comprehensive.py:178: in test_txt_encoding_handling\n    text = ingestor._extract_txt_text('test.txt')\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'DocumentIngestor' object has no attribute '_extract_txt_text'. Did you mean: '_extract_pdf_text'?\n______________ TestMarkdownProcessing.test_md_metadata_extraction ______________\ntests/test_document_ingestor_comprehensive.py:196: in test_md_metadata_extraction\n    metadata = ingestor._extract_md_metadata('test.md')\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'DocumentIngestor' object has no attribute '_extract_md_metadata'. Did you mean: '_extract_pdf_metadata'?\n________________ TestMarkdownProcessing.test_md_text_extraction ________________\ntests/test_document_ingestor_comprehensive.py:206: in test_md_text_extraction\n    text = ingestor._extract_md_text('test.md')\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'DocumentIngestor' object has no attribute '_extract_md_text'. Did you mean: '_extract_pdf_text'?\n_____________ TestMarkdownProcessing.test_md_frontmatter_handling ______________\ntests/test_document_ingestor_comprehensive.py:224: in test_md_frontmatter_handling\n    text = ingestor._extract_md_text('test.md')\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'DocumentIngestor' object has no attribute '_extract_md_text'. Did you mean: '_extract_pdf_text'?\n_______________ TestDOCXProcessing.test_docx_metadata_extraction _______________\ntests/test_document_ingestor_comprehensive.py:247: in test_docx_metadata_extraction\n    with patch('document_ingestor.Document') as mock_doc:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <module 'document_ingestor' from '/workspace/document_ingestor.py'> does not have the attribute 'Document'\n_________________ TestDOCXProcessing.test_docx_text_extraction _________________\ntests/test_document_ingestor_comprehensive.py:264: in test_docx_text_extraction\n    with patch('document_ingestor.Document') as mock_doc:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <module 'document_ingestor' from '/workspace/document_ingestor.py'> does not have the attribute 'Document'\n_________________ TestDOCXProcessing.test_docx_error_handling __________________\ntests/test_document_ingestor_comprehensive.py:275: in test_docx_error_handling\n    with patch('document_ingestor.Document') as mock_doc:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <module 'document_ingestor' from '/workspace/document_ingestor.py'> does not have the attribute 'Document'\n_______________ TestEPUBProcessing.test_epub_metadata_extraction _______________\ntests/test_document_ingestor_comprehensive.py:293: in test_epub_metadata_extraction\n    metadata = ingestor._extract_epub_metadata('test.epub')\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: DocumentIngestor._extract_epub_metadata() missing 1 required positional argument: 'metadata'\n_________________ TestEPUBProcessing.test_epub_text_extraction _________________\ntests/test_document_ingestor_comprehensive.py:304: in test_epub_text_extraction\n    assert isinstance(text, str)\nE   assert False\nE    +  where False = isinstance(<coroutine object DocumentIngestor._extract_epub_text at 0x7f27f8d1c580>, str)\n_________________ TestDocumentMetadata.test_metadata_creation __________________\ntests/test_document_ingestor_comprehensive.py:313: in test_metadata_creation\n    metadata = DocumentMetadata(\nE   pydantic_core._pydantic_core.ValidationError: 6 validation errors for DocumentMetadata\nE   source_id\nE     Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\nE   original_filename\nE     Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\nE   file_type\nE     Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\nE   ingestion_timestamp\nE     Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\nE   chunk_count\nE     Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\nE   checksum\nE     Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\n________________ TestDocumentMetadata.test_metadata_validation _________________\ntests/test_document_ingestor_comprehensive.py:334: in test_metadata_validation\n    metadata = DocumentMetadata(\nE   pydantic_core._pydantic_core.ValidationError: 6 validation errors for DocumentMetadata\nE   source_id\nE     Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\nE   original_filename\nE     Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\nE   file_type\nE     Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\nE   ingestion_timestamp\nE     Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\nE   chunk_count\nE     Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\nE   checksum\nE     Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\n___________________ TestDocumentIngestion.test_pdf_ingestion ___________________\ntests/test_document_ingestor_comprehensive.py:366: in test_pdf_ingestion\n    assert result.title == 'Test PDF'\n           ^^^^^^^^^^^^\nE   AttributeError: 'coroutine' object has no attribute 'title'\n___________________ TestDocumentIngestion.test_txt_ingestion ___________________\ntests/test_document_ingestor_comprehensive.py:377: in test_txt_ingestion\n    with patch.object(ingestor, '_extract_txt_metadata', return_value=mock_metadata):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <document_ingestor.DocumentIngestor object at 0x7f27f8ed5220> does not have the attribute '_extract_txt_metadata'\n___________________ TestDocumentIngestion.test_md_ingestion ____________________\ntests/test_document_ingestor_comprehensive.py:392: in test_md_ingestion\n    with patch.object(ingestor, '_extract_md_metadata', return_value=mock_metadata):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <document_ingestor.DocumentIngestor object at 0x7f27f8ed7100> does not have the attribute '_extract_md_metadata'\n__________________ TestDocumentIngestion.test_docx_ingestion ___________________\ntests/test_document_ingestor_comprehensive.py:414: in test_docx_ingestion\n    assert result.title == 'Test DOCX'\n           ^^^^^^^^^^^^\nE   AttributeError: 'coroutine' object has no attribute 'title'\n__________________ TestDocumentIngestion.test_epub_ingestion ___________________\ntests/test_document_ingestor_comprehensive.py:432: in test_epub_ingestion\n    assert result.title == 'Test EPUB'\n           ^^^^^^^^^^^^\nE   AttributeError: 'coroutine' object has no attribute 'title'\n___________________ TestErrorHandling.test_nonexistent_file ____________________\ntests/test_document_ingestor_comprehensive.py:447: in test_nonexistent_file\n    with pytest.raises(FileNotFoundError):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   Failed: DID NOT RAISE <class 'FileNotFoundError'>\n_____________________ TestErrorHandling.test_corrupted_pdf _____________________\ntests/test_document_ingestor_comprehensive.py:455: in test_corrupted_pdf\n    with pytest.raises(Exception, match=\"Corrupted PDF\"):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   Failed: DID NOT RAISE <class 'Exception'>\n____________________ TestErrorHandling.test_corrupted_docx _____________________\ntests/test_document_ingestor_comprehensive.py:460: in test_corrupted_docx\n    with patch('document_ingestor.Document') as mock_doc:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <module 'document_ingestor' from '/workspace/document_ingestor.py'> does not have the attribute 'Document'\n___________________ TestErrorHandling.test_permission_error ____________________\ntests/test_document_ingestor_comprehensive.py:469: in test_permission_error\n    with pytest.raises(PermissionError):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   Failed: DID NOT RAISE <class 'PermissionError'>\n____________________ TestErrorHandling.test_encoding_error _____________________\ntests/test_document_ingestor_comprehensive.py:475: in test_encoding_error\n    with pytest.raises(UnicodeDecodeError):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   Failed: DID NOT RAISE <class 'UnicodeDecodeError'>\n___________________ TestPerformance.test_large_file_handling ___________________\ntests/test_document_ingestor_comprehensive.py:496: in test_large_file_handling\n    assert len(result.content) > 100000\n               ^^^^^^^^^^^^^^\nE   AttributeError: 'coroutine' object has no attribute 'content'\n__________________ TestPerformance.test_ingestion_performance __________________\ntests/test_document_ingestor_comprehensive.py:505: in test_ingestion_performance\n    with patch.object(ingestor, '_extract_txt_metadata', return_value=mock_metadata):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <document_ingestor.DocumentIngestor object at 0x7f27f8c09ba0> does not have the attribute '_extract_txt_metadata'\n_______________ TestIntegration.test_memory_manager_integration ________________\ntests/test_document_ingestor_comprehensive.py:533: in test_memory_manager_integration\n    with patch.object(ingestor, '_extract_txt_metadata', return_value=mock_metadata):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <document_ingestor.DocumentIngestor object at 0x7f27f8ed7ce0> does not have the attribute '_extract_txt_metadata'\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:09,376 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:09,376 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:09,728 - memory_manager - INFO - Memory manager initialized with persist directory: memory_db\n------------------------------ Captured log call -------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: memory_db\n____________________ TestIntegration.test_agent_integration ____________________\ntests/test_document_ingestor_comprehensive.py:548: in test_agent_integration\n    with patch.object(ingestor, '_extract_txt_metadata', return_value=mock_metadata):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <document_ingestor.DocumentIngestor object at 0x7f27f8e590f0> does not have the attribute '_extract_txt_metadata'\n=============================== warnings summary ===============================\n../home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21\n  /home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n    warnings.warn(\n\ntests/test_document_ingestor_comprehensive.py::TestDocumentIngestorCore::test_unsupported_format\n  /workspace/tests/test_document_ingestor_comprehensive.py:63: RuntimeWarning: coroutine 'DocumentIngestor.ingest_document' was never awaited\n    ingestor.ingest_document('test.xyz')\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_error_handling\n  /workspace/tests/test_document_ingestor_comprehensive.py:139: RuntimeWarning: coroutine 'DocumentIngestor._extract_pdf_text' was never awaited\n    ingestor._extract_pdf_text('test.pdf')\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_nonexistent_file\n  /workspace/tests/test_document_ingestor_comprehensive.py:448: RuntimeWarning: coroutine 'DocumentIngestor.ingest_document' was never awaited\n    ingestor.ingest_document('nonexistent.pdf')\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_corrupted_pdf\n  /workspace/tests/test_document_ingestor_comprehensive.py:456: RuntimeWarning: coroutine 'DocumentIngestor.ingest_document' was never awaited\n    ingestor.ingest_document('corrupted.pdf')\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_permission_error\n  /workspace/tests/test_document_ingestor_comprehensive.py:470: RuntimeWarning: coroutine 'DocumentIngestor.ingest_document' was never awaited\n    ingestor.ingest_document('protected.txt')\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\ntests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_encoding_error\n  /workspace/tests/test_document_ingestor_comprehensive.py:476: RuntimeWarning: coroutine 'DocumentIngestor.ingest_document' was never awaited\n    ingestor.ingest_document('invalid_encoding.txt')\n  Enable tracemalloc to get traceback where the object was allocated.\n  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============================= slowest 10 durations =============================\n0.43s call     tests/test_document_ingestor_comprehensive.py::TestIntegration::test_memory_manager_integration\n0.00s call     tests/test_document_ingestor_comprehensive.py::TestTXTProcessing::test_txt_encoding_handling\n0.00s call     tests/test_document_ingestor_comprehensive.py::TestTXTProcessing::test_txt_text_extraction\n0.00s call     tests/test_document_ingestor_comprehensive.py::TestPerformance::test_large_file_handling\n0.00s call     tests/test_document_ingestor_comprehensive.py::TestMarkdownProcessing::test_md_frontmatter_handling\n0.00s call     tests/test_document_ingestor_comprehensive.py::TestMarkdownProcessing::test_md_text_extraction\n0.00s call     tests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_metadata_extraction\n0.00s call     tests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_text_extraction\n0.00s call     tests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_multiple_pages\n0.00s setup    tests/test_document_ingestor_comprehensive.py::TestDocumentIngestorCore::test_ingestor_initialization\n=========================== short test summary info ============================\nFAILED tests/test_document_ingestor_comprehensive.py::TestDocumentIngestorCore::test_format_detection - AttributeError: 'DocumentIngestor' object has no attribute '_detect_format'\nFAILED tests/test_document_ingestor_comprehensive.py::TestDocumentIngestorCore::test_unsupported_format - Failed: DID NOT RAISE <class 'ValueError'>\nFAILED tests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_metadata_extraction - TypeError: DocumentIngestor._extract_pdf_metadata() missing 1 required positional argument: 'metadata'\nFAILED tests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_text_extraction - AssertionError: assert <coroutine object DocumentIngestor._extract_pdf_text at 0x7f27f8f46240> == 'This is test content from PDF document.'\nFAILED tests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_multiple_pages - TypeError: argument of type 'coroutine' is not iterable\nFAILED tests/test_document_ingestor_comprehensive.py::TestPDFProcessing::test_pdf_error_handling - Failed: DID NOT RAISE <class 'Exception'>\nFAILED tests/test_document_ingestor_comprehensive.py::TestTXTProcessing::test_txt_metadata_extraction - AttributeError: 'DocumentIngestor' object has no attribute '_extract_txt_metadata'. Did you mean: '_extract_pdf_metadata'?\nFAILED tests/test_document_ingestor_comprehensive.py::TestTXTProcessing::test_txt_text_extraction - AttributeError: 'DocumentIngestor' object has no attribute '_extract_txt_text'. Did you mean: '_extract_pdf_text'?\nFAILED tests/test_document_ingestor_comprehensive.py::TestTXTProcessing::test_txt_encoding_handling - AttributeError: 'DocumentIngestor' object has no attribute '_extract_txt_text'. Did you mean: '_extract_pdf_text'?\nFAILED tests/test_document_ingestor_comprehensive.py::TestMarkdownProcessing::test_md_metadata_extraction - AttributeError: 'DocumentIngestor' object has no attribute '_extract_md_metadata'. Did you mean: '_extract_pdf_metadata'?\nFAILED tests/test_document_ingestor_comprehensive.py::TestMarkdownProcessing::test_md_text_extraction - AttributeError: 'DocumentIngestor' object has no attribute '_extract_md_text'. Did you mean: '_extract_pdf_text'?\nFAILED tests/test_document_ingestor_comprehensive.py::TestMarkdownProcessing::test_md_frontmatter_handling - AttributeError: 'DocumentIngestor' object has no attribute '_extract_md_text'. Did you mean: '_extract_pdf_text'?\nFAILED tests/test_document_ingestor_comprehensive.py::TestDOCXProcessing::test_docx_metadata_extraction - AttributeError: <module 'document_ingestor' from '/workspace/document_ingestor.py'> does not have the attribute 'Document'\nFAILED tests/test_document_ingestor_comprehensive.py::TestDOCXProcessing::test_docx_text_extraction - AttributeError: <module 'document_ingestor' from '/workspace/document_ingestor.py'> does not have the attribute 'Document'\nFAILED tests/test_document_ingestor_comprehensive.py::TestDOCXProcessing::test_docx_error_handling - AttributeError: <module 'document_ingestor' from '/workspace/document_ingestor.py'> does not have the attribute 'Document'\nFAILED tests/test_document_ingestor_comprehensive.py::TestEPUBProcessing::test_epub_metadata_extraction - TypeError: DocumentIngestor._extract_epub_metadata() missing 1 required positional argument: 'metadata'\nFAILED tests/test_document_ingestor_comprehensive.py::TestEPUBProcessing::test_epub_text_extraction - assert False\n +  where False = isinstance(<coroutine object DocumentIngestor._extract_epub_text at 0x7f27f8d1c580>, str)\nFAILED tests/test_document_ingestor_comprehensive.py::TestDocumentMetadata::test_metadata_creation - pydantic_core._pydantic_core.ValidationError: 6 validation errors for DocumentMetadata\nsource_id\n  Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\noriginal_filename\n  Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nfile_type\n  Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\ningestion_timestamp\n  Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nchunk_count\n  Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nchecksum\n  Field required [type=missing, input_value={'title': 'Test Document'..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nFAILED tests/test_document_ingestor_comprehensive.py::TestDocumentMetadata::test_metadata_validation - pydantic_core._pydantic_core.ValidationError: 6 validation errors for DocumentMetadata\nsource_id\n  Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\noriginal_filename\n  Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nfile_type\n  Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\ningestion_timestamp\n  Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nchunk_count\n  Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nchecksum\n  Field required [type=missing, input_value={'title': 'Test', 'author..., 'file_format': '.pdf'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nFAILED tests/test_document_ingestor_comprehensive.py::TestDocumentIngestion::test_pdf_ingestion - AttributeError: 'coroutine' object has no attribute 'title'\nFAILED tests/test_document_ingestor_comprehensive.py::TestDocumentIngestion::test_txt_ingestion - AttributeError: <document_ingestor.DocumentIngestor object at 0x7f27f8ed5220> does not have the attribute '_extract_txt_metadata'\nFAILED tests/test_document_ingestor_comprehensive.py::TestDocumentIngestion::test_md_ingestion - AttributeError: <document_ingestor.DocumentIngestor object at 0x7f27f8ed7100> does not have the attribute '_extract_md_metadata'\nFAILED tests/test_document_ingestor_comprehensive.py::TestDocumentIngestion::test_docx_ingestion - AttributeError: 'coroutine' object has no attribute 'title'\nFAILED tests/test_document_ingestor_comprehensive.py::TestDocumentIngestion::test_epub_ingestion - AttributeError: 'coroutine' object has no attribute 'title'\nFAILED tests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_nonexistent_file - Failed: DID NOT RAISE <class 'FileNotFoundError'>\nFAILED tests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_corrupted_pdf - Failed: DID NOT RAISE <class 'Exception'>\nFAILED tests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_corrupted_docx - AttributeError: <module 'document_ingestor' from '/workspace/document_ingestor.py'> does not have the attribute 'Document'\nFAILED tests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_permission_error - Failed: DID NOT RAISE <class 'PermissionError'>\nFAILED tests/test_document_ingestor_comprehensive.py::TestErrorHandling::test_encoding_error - Failed: DID NOT RAISE <class 'UnicodeDecodeError'>\nFAILED tests/test_document_ingestor_comprehensive.py::TestPerformance::test_large_file_handling - AttributeError: 'coroutine' object has no attribute 'content'\nFAILED tests/test_document_ingestor_comprehensive.py::TestPerformance::test_ingestion_performance - AttributeError: <document_ingestor.DocumentIngestor object at 0x7f27f8c09ba0> does not have the attribute '_extract_txt_metadata'\nFAILED tests/test_document_ingestor_comprehensive.py::TestIntegration::test_memory_manager_integration - AttributeError: <document_ingestor.DocumentIngestor object at 0x7f27f8ed7ce0> does not have the attribute '_extract_txt_metadata'\nFAILED tests/test_document_ingestor_comprehensive.py::TestIntegration::test_agent_integration - AttributeError: <document_ingestor.DocumentIngestor object at 0x7f27f8e590f0> does not have the attribute '_extract_txt_metadata'\n=================== 33 failed, 2 passed, 7 warnings in 0.94s ===================\n",
      "stderr": ""
    },
    {
      "name": "Memory Manager Comprehensive",
      "file": "tests/test_memory_manager_comprehensive.py",
      "category": "unit",
      "status": "FAILED",
      "duration": 14.572707414627075,
      "passed": 7,
      "failed": 23,
      "skipped": 0,
      "errors": 0,
      "total": 30,
      "returncode": 1,
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.13.3, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /workspace\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, asyncio-1.1.0, mock-3.15.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 30 items\n\ntests/test_memory_manager_comprehensive.py::TestMemoryManagerCore::test_memory_manager_initialization FAILED [  3%]\ntests/test_memory_manager_comprehensive.py::TestMemoryManagerCore::test_memory_manager_configuration FAILED [  6%]\ntests/test_memory_manager_comprehensive.py::TestMemoryManagerCore::test_memory_manager_stats PASSED [ 10%]\ntests/test_memory_manager_comprehensive.py::TestMemoryEntry::test_memory_entry_creation PASSED [ 13%]\ntests/test_memory_manager_comprehensive.py::TestMemoryEntry::test_memory_entry_validation PASSED [ 16%]\ntests/test_memory_manager_comprehensive.py::TestMemoryEntry::test_memory_entry_metadata FAILED [ 20%]\ntests/test_memory_manager_comprehensive.py::TestRetrievalResult::test_retrieval_result_creation PASSED [ 23%]\ntests/test_memory_manager_comprehensive.py::TestRetrievalResult::test_retrieval_result_validation PASSED [ 26%]\ntests/test_memory_manager_comprehensive.py::TestDocumentStorage::test_store_document_chunks FAILED [ 30%]\ntests/test_memory_manager_comprehensive.py::TestDocumentStorage::test_store_single_chunk FAILED [ 33%]\ntests/test_memory_manager_comprehensive.py::TestDocumentStorage::test_store_empty_chunks FAILED [ 36%]\ntests/test_memory_manager_comprehensive.py::TestDocumentRetrieval::test_retrieve_relevant_chunks FAILED [ 40%]\ntests/test_memory_manager_comprehensive.py::TestDocumentRetrieval::test_retrieve_with_filters FAILED [ 43%]\ntests/test_memory_manager_comprehensive.py::TestDocumentRetrieval::test_retrieve_empty_database FAILED [ 46%]\ntests/test_memory_manager_comprehensive.py::TestRAGPipeline::test_complete_rag_pipeline FAILED [ 50%]\ntests/test_memory_manager_comprehensive.py::TestRAGPipeline::test_context_assembly FAILED [ 53%]\ntests/test_memory_manager_comprehensive.py::TestRAGPipeline::test_context_length_management FAILED [ 56%]\ntests/test_memory_manager_comprehensive.py::TestMemoryOperations::test_add_agent_notes FAILED [ 60%]\ntests/test_memory_manager_comprehensive.py::TestMemoryOperations::test_search_by_tags FAILED [ 63%]\ntests/test_memory_manager_comprehensive.py::TestMemoryOperations::test_get_stats FAILED [ 66%]\ntests/test_memory_manager_comprehensive.py::TestMemoryOperations::test_clear_memory FAILED [ 70%]\ntests/test_memory_manager_comprehensive.py::TestErrorHandling::test_invalid_chunk_data FAILED [ 73%]\ntests/test_memory_manager_comprehensive.py::TestErrorHandling::test_retrieval_with_invalid_query FAILED [ 76%]\ntests/test_memory_manager_comprehensive.py::TestErrorHandling::test_retrieval_with_invalid_parameters FAILED [ 80%]\ntests/test_memory_manager_comprehensive.py::TestPerformance::test_large_document_handling FAILED [ 83%]\ntests/test_memory_manager_comprehensive.py::TestPerformance::test_retrieval_performance FAILED [ 86%]\ntests/test_memory_manager_comprehensive.py::TestPerformance::test_concurrent_operations FAILED [ 90%]\ntests/test_memory_manager_comprehensive.py::TestIntegration::test_llm_client_integration FAILED [ 93%]\ntests/test_memory_manager_comprehensive.py::TestIntegration::test_agent_integration PASSED [ 96%]\ntests/test_memory_manager_comprehensive.py::TestIntegration::test_document_ingestor_integration PASSED [100%]\n\n=================================== FAILURES ===================================\n___________ TestMemoryManagerCore.test_memory_manager_initialization ___________\ntests/test_memory_manager_comprehensive.py:38: in test_memory_manager_initialization\n    assert hasattr(memory_manager, 'vector_store')\nE   AssertionError: assert False\nE    +  where False = hasattr(<memory_manager.MemoryManager object at 0x7fdeb6904d70>, 'vector_store')\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:14,370 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:14,370 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:14,690 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpmfzqvc2q\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpmfzqvc2q\n___________ TestMemoryManagerCore.test_memory_manager_configuration ____________\ntests/test_memory_manager_comprehensive.py:43: in test_memory_manager_configuration\n    assert memory_manager.collection_name == 'documents'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'MemoryManager' object has no attribute 'collection_name'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:14,742 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:14,743 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:15,018 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmphsxj4qh7\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmphsxj4qh7\n__________________ TestMemoryEntry.test_memory_entry_metadata __________________\ntests/test_memory_manager_comprehensive.py:101: in test_memory_entry_metadata\n    entry = MemoryEntry(\nE   pydantic_core._pydantic_core.ValidationError: 3 validation errors for MemoryEntry\nE   metadata.page_number\nE     Input should be a valid string [type=string_type, input_value=1, input_type=int]\nE       For further information visit https://errors.pydantic.dev/2.11/v/string_type\nE   metadata.tags\nE     Input should be a valid string [type=string_type, input_value=['important', 'reference'], input_type=list]\nE       For further information visit https://errors.pydantic.dev/2.11/v/string_type\nE   metadata.confidence\nE     Input should be a valid string [type=string_type, input_value=0.95, input_type=float]\nE       For further information visit https://errors.pydantic.dev/2.11/v/string_type\n________________ TestDocumentStorage.test_store_document_chunks ________________\ntests/test_memory_manager_comprehensive.py:169: in test_store_document_chunks\n    MemoryEntry(\nE   pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nE   metadata.chunk_index\nE     Input should be a valid string [type=string_type, input_value=0, input_type=int]\nE       For further information visit https://errors.pydantic.dev/2.11/v/string_type\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:15,363 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:15,363 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:15,640 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpfdmr497u\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpfdmr497u\n_________________ TestDocumentStorage.test_store_single_chunk __________________\ntests/test_memory_manager_comprehensive.py:205: in test_store_single_chunk\n    result = await memory_manager.store_document_chunks([chunk])\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:15,682 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:15,682 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:15,956 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpmid1pip3\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpmid1pip3\n_________________ TestDocumentStorage.test_store_empty_chunks __________________\ntests/test_memory_manager_comprehensive.py:214: in test_store_empty_chunks\n    result = await memory_manager.store_document_chunks([])\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:15,992 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:15,992 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:16,295 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmp4bylhatm\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmp4bylhatm\n_____________ TestDocumentRetrieval.test_retrieve_relevant_chunks ______________\ntests/test_memory_manager_comprehensive.py:257: in test_retrieve_relevant_chunks\n    await memory_manager.store_document_chunks(chunks)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:16,330 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:16,330 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:16,601 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmp5m6s71u9\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmp5m6s71u9\n_______________ TestDocumentRetrieval.test_retrieve_with_filters _______________\ntests/test_memory_manager_comprehensive.py:292: in test_retrieve_with_filters\n    await memory_manager.store_document_chunks(chunks)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:16,641 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:16,641 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:16,939 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpluqhutux\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpluqhutux\n______________ TestDocumentRetrieval.test_retrieve_empty_database ______________\ntests/test_memory_manager_comprehensive.py:309: in test_retrieve_empty_database\n    results = await memory_manager.retrieve_relevant_chunks(\nE   TypeError: MemoryManager.retrieve_relevant_chunks() got an unexpected keyword argument 'max_results'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:16,976 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:16,977 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:17,252 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpqlyl6r26\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpqlyl6r26\n__________________ TestRAGPipeline.test_complete_rag_pipeline __________________\ntests/test_memory_manager_comprehensive.py:355: in test_complete_rag_pipeline\n    await memory_manager.store_document_chunks(knowledge_chunks)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:17,293 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:17,293 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:17,756 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpftwxdbr0\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpftwxdbr0\n____________________ TestRAGPipeline.test_context_assembly _____________________\ntests/test_memory_manager_comprehensive.py:377: in test_context_assembly\n    MemoryEntry(\nE   pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nE   metadata.relevance\nE     Input should be a valid string [type=string_type, input_value=0.9, input_type=float]\nE       For further information visit https://errors.pydantic.dev/2.11/v/string_type\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:17,798 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:17,798 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:18,070 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmphyx6lj_2\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmphyx6lj_2\n________________ TestRAGPipeline.test_context_length_management ________________\ntests/test_memory_manager_comprehensive.py:415: in test_context_length_management\n    chunk = MemoryEntry(\nE   pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nE   metadata.chunk_index\nE     Input should be a valid string [type=string_type, input_value=0, input_type=int]\nE       For further information visit https://errors.pydantic.dev/2.11/v/string_type\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:18,108 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:18,109 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:18,429 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmp0emoe1u1\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmp0emoe1u1\n__________________ TestMemoryOperations.test_add_agent_notes ___________________\ntests/test_memory_manager_comprehensive.py:463: in test_add_agent_notes\n    result = await memory_manager.add_agent_notes(note)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: MemoryManager.add_agent_notes() missing 1 required positional argument: 'agent_id'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:18,472 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:18,472 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:18,736 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmp610ty1jt\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmp610ty1jt\n___________________ TestMemoryOperations.test_search_by_tags ___________________\ntests/test_memory_manager_comprehensive.py:473: in test_search_by_tags\n    MemoryEntry(\nE   pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nE   metadata.tags\nE     Input should be a valid string [type=string_type, input_value=['AI', 'technology', 'important'], input_type=list]\nE       For further information visit https://errors.pydantic.dev/2.11/v/string_type\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:18,777 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:18,777 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:19,039 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpm4rwxtdx\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpm4rwxtdx\n_____________________ TestMemoryOperations.test_get_stats ______________________\ntests/test_memory_manager_comprehensive.py:518: in test_get_stats\n    await memory_manager.store_document_chunks(chunks)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:19,082 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:19,082 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:19,354 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmp3n9h8_rk\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmp3n9h8_rk\n____________________ TestMemoryOperations.test_clear_memory ____________________\ntests/test_memory_manager_comprehensive.py:542: in test_clear_memory\n    await memory_manager.store_document_chunks(chunks)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:19,392 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:19,393 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:19,662 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpo3xvm9fx\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpo3xvm9fx\n__________________ TestErrorHandling.test_invalid_chunk_data ___________________\ntests/test_memory_manager_comprehensive.py:575: in test_invalid_chunk_data\n    await memory_manager.store_document_chunks(None)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:19,721 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:19,721 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:19,976 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpfw_rosi_\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpfw_rosi_\n_____________ TestErrorHandling.test_retrieval_with_invalid_query ______________\ntests/test_memory_manager_comprehensive.py:585: in test_retrieval_with_invalid_query\n    results = await memory_manager.retrieve_relevant_chunks(\nE   TypeError: MemoryManager.retrieve_relevant_chunks() got an unexpected keyword argument 'max_results'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:20,015 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:20,015 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:20,278 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmphqtq2_wc\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmphqtq2_wc\n___________ TestErrorHandling.test_retrieval_with_invalid_parameters ___________\ntests/test_memory_manager_comprehensive.py:604: in test_retrieval_with_invalid_parameters\n    results = await memory_manager.retrieve_relevant_chunks(\nE   TypeError: MemoryManager.retrieve_relevant_chunks() got an unexpected keyword argument 'max_results'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:20,314 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:20,314 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:20,563 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmp700qv5uf\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmp700qv5uf\n_________________ TestPerformance.test_large_document_handling _________________\ntests/test_memory_manager_comprehensive.py:642: in test_large_document_handling\n    chunk = MemoryEntry(\nE   pydantic_core._pydantic_core.ValidationError: 2 validation errors for MemoryEntry\nE   metadata.chunk_index\nE     Input should be a valid string [type=string_type, input_value=0, input_type=int]\nE       For further information visit https://errors.pydantic.dev/2.11/v/string_type\nE   metadata.size\nE     Input should be a valid string [type=string_type, input_value=7, input_type=int]\nE       For further information visit https://errors.pydantic.dev/2.11/v/string_type\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:20,602 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:20,602 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:22,448 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpd45plxd0\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpd45plxd0\n__________________ TestPerformance.test_retrieval_performance __________________\ntests/test_memory_manager_comprehensive.py:668: in test_retrieval_performance\n    chunk = MemoryEntry(\nE   pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nE   metadata.chunk_index\nE     Input should be a valid string [type=string_type, input_value=0, input_type=int]\nE       For further information visit https://errors.pydantic.dev/2.11/v/string_type\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:22,491 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:22,491 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:22,760 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmp8fzlmyja\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmp8fzlmyja\n__________________ TestPerformance.test_concurrent_operations __________________\ntests/test_memory_manager_comprehensive.py:717: in test_concurrent_operations\n    results = await asyncio.gather(*tasks)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntests/test_memory_manager_comprehensive.py:699: in store_chunks\n    chunk = MemoryEntry(\nE   pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nE   metadata.concurrent_test\nE     Input should be a valid string [type=string_type, input_value=True, input_type=bool]\nE       For further information visit https://errors.pydantic.dev/2.11/v/string_type\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:22,794 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:22,794 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:23,070 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpmlzxplo7\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpmlzxplo7\n_________________ TestIntegration.test_llm_client_integration __________________\ntests/test_memory_manager_comprehensive.py:761: in test_llm_client_integration\n    assert \"Test content for LLM\" in context\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: argument of type 'coroutine' is not iterable\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:23,113 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:23,113 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:23,391 - memory_manager - INFO - Memory manager initialized with persist directory: /tmp/tmpkatfczol\n------------------------------ Captured log setup ------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: /tmp/tmpkatfczol\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:23,392 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdeb6705fd0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:23,392 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:23,393 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log call -------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdeb6705fd0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n=============================== warnings summary ===============================\n../home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21\n  /home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============================= slowest 10 durations =============================\n1.88s setup    tests/test_memory_manager_comprehensive.py::TestPerformance::test_large_document_handling\n0.50s setup    tests/test_memory_manager_comprehensive.py::TestRAGPipeline::test_complete_rag_pipeline\n0.45s setup    tests/test_memory_manager_comprehensive.py::TestIntegration::test_document_ingestor_integration\n0.42s setup    tests/test_memory_manager_comprehensive.py::TestMemoryManagerCore::test_memory_manager_initialization\n0.35s setup    tests/test_memory_manager_comprehensive.py::TestRAGPipeline::test_context_length_management\n0.33s setup    tests/test_memory_manager_comprehensive.py::TestDocumentStorage::test_store_empty_chunks\n0.33s setup    tests/test_memory_manager_comprehensive.py::TestDocumentRetrieval::test_retrieve_with_filters\n0.32s setup    tests/test_memory_manager_comprehensive.py::TestIntegration::test_agent_integration\n0.31s setup    tests/test_memory_manager_comprehensive.py::TestIntegration::test_llm_client_integration\n0.31s setup    tests/test_memory_manager_comprehensive.py::TestMemoryOperations::test_get_stats\n=========================== short test summary info ============================\nFAILED tests/test_memory_manager_comprehensive.py::TestMemoryManagerCore::test_memory_manager_initialization - AssertionError: assert False\n +  where False = hasattr(<memory_manager.MemoryManager object at 0x7fdeb6904d70>, 'vector_store')\nFAILED tests/test_memory_manager_comprehensive.py::TestMemoryManagerCore::test_memory_manager_configuration - AttributeError: 'MemoryManager' object has no attribute 'collection_name'\nFAILED tests/test_memory_manager_comprehensive.py::TestMemoryEntry::test_memory_entry_metadata - pydantic_core._pydantic_core.ValidationError: 3 validation errors for MemoryEntry\nmetadata.page_number\n  Input should be a valid string [type=string_type, input_value=1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nmetadata.tags\n  Input should be a valid string [type=string_type, input_value=['important', 'reference'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nmetadata.confidence\n  Input should be a valid string [type=string_type, input_value=0.95, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nFAILED tests/test_memory_manager_comprehensive.py::TestDocumentStorage::test_store_document_chunks - pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nmetadata.chunk_index\n  Input should be a valid string [type=string_type, input_value=0, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nFAILED tests/test_memory_manager_comprehensive.py::TestDocumentStorage::test_store_single_chunk - TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\nFAILED tests/test_memory_manager_comprehensive.py::TestDocumentStorage::test_store_empty_chunks - TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\nFAILED tests/test_memory_manager_comprehensive.py::TestDocumentRetrieval::test_retrieve_relevant_chunks - TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\nFAILED tests/test_memory_manager_comprehensive.py::TestDocumentRetrieval::test_retrieve_with_filters - TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\nFAILED tests/test_memory_manager_comprehensive.py::TestDocumentRetrieval::test_retrieve_empty_database - TypeError: MemoryManager.retrieve_relevant_chunks() got an unexpected keyword argument 'max_results'\nFAILED tests/test_memory_manager_comprehensive.py::TestRAGPipeline::test_complete_rag_pipeline - TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\nFAILED tests/test_memory_manager_comprehensive.py::TestRAGPipeline::test_context_assembly - pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nmetadata.relevance\n  Input should be a valid string [type=string_type, input_value=0.9, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nFAILED tests/test_memory_manager_comprehensive.py::TestRAGPipeline::test_context_length_management - pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nmetadata.chunk_index\n  Input should be a valid string [type=string_type, input_value=0, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nFAILED tests/test_memory_manager_comprehensive.py::TestMemoryOperations::test_add_agent_notes - TypeError: MemoryManager.add_agent_notes() missing 1 required positional argument: 'agent_id'\nFAILED tests/test_memory_manager_comprehensive.py::TestMemoryOperations::test_search_by_tags - pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nmetadata.tags\n  Input should be a valid string [type=string_type, input_value=['AI', 'technology', 'important'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nFAILED tests/test_memory_manager_comprehensive.py::TestMemoryOperations::test_get_stats - TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\nFAILED tests/test_memory_manager_comprehensive.py::TestMemoryOperations::test_clear_memory - TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\nFAILED tests/test_memory_manager_comprehensive.py::TestErrorHandling::test_invalid_chunk_data - TypeError: MemoryManager.store_document_chunks() missing 1 required positional argument: 'chunks'\nFAILED tests/test_memory_manager_comprehensive.py::TestErrorHandling::test_retrieval_with_invalid_query - TypeError: MemoryManager.retrieve_relevant_chunks() got an unexpected keyword argument 'max_results'\nFAILED tests/test_memory_manager_comprehensive.py::TestErrorHandling::test_retrieval_with_invalid_parameters - TypeError: MemoryManager.retrieve_relevant_chunks() got an unexpected keyword argument 'max_results'\nFAILED tests/test_memory_manager_comprehensive.py::TestPerformance::test_large_document_handling - pydantic_core._pydantic_core.ValidationError: 2 validation errors for MemoryEntry\nmetadata.chunk_index\n  Input should be a valid string [type=string_type, input_value=0, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nmetadata.size\n  Input should be a valid string [type=string_type, input_value=7, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nFAILED tests/test_memory_manager_comprehensive.py::TestPerformance::test_retrieval_performance - pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nmetadata.chunk_index\n  Input should be a valid string [type=string_type, input_value=0, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nFAILED tests/test_memory_manager_comprehensive.py::TestPerformance::test_concurrent_operations - pydantic_core._pydantic_core.ValidationError: 1 validation error for MemoryEntry\nmetadata.concurrent_test\n  Input should be a valid string [type=string_type, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nFAILED tests/test_memory_manager_comprehensive.py::TestIntegration::test_llm_client_integration - TypeError: argument of type 'coroutine' is not iterable\n=================== 23 failed, 7 passed, 1 warning in 9.94s ====================\n",
      "stderr": "/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/unraisableexception.py:33: RuntimeWarning: coroutine 'MemoryManager.get_context_for_generation' was never awaited\n  gc.collect()\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
    },
    {
      "name": "LLM Client Comprehensive",
      "file": "tests/test_llm_client_comprehensive.py",
      "category": "unit",
      "status": "FAILED",
      "duration": 5.87886643409729,
      "passed": 6,
      "failed": 29,
      "skipped": 0,
      "errors": 0,
      "total": 35,
      "returncode": 1,
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.13.3, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /workspace\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, asyncio-1.1.0, mock-3.15.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 35 items\n\ntests/test_llm_client_comprehensive.py::TestLLMClientCore::test_llm_client_initialization FAILED [  2%]\ntests/test_llm_client_comprehensive.py::TestLLMClientCore::test_llm_client_configuration FAILED [  5%]\ntests/test_llm_client_comprehensive.py::TestLLMClientCore::test_llm_client_providers FAILED [  8%]\ntests/test_llm_client_comprehensive.py::TestLLMRequest::test_llm_request_creation PASSED [ 11%]\ntests/test_llm_client_comprehensive.py::TestLLMRequest::test_llm_request_defaults FAILED [ 14%]\ntests/test_llm_client_comprehensive.py::TestLLMRequest::test_llm_request_validation PASSED [ 17%]\ntests/test_llm_client_comprehensive.py::TestLLMResponse::test_llm_response_creation PASSED [ 20%]\ntests/test_llm_client_comprehensive.py::TestLLMResponse::test_llm_response_defaults FAILED [ 22%]\ntests/test_llm_client_comprehensive.py::TestOpenAIProvider::test_openai_generate FAILED [ 25%]\ntests/test_llm_client_comprehensive.py::TestOpenAIProvider::test_openai_error_handling FAILED [ 28%]\ntests/test_llm_client_comprehensive.py::TestOpenAIProvider::test_openai_rate_limiting FAILED [ 31%]\ntests/test_llm_client_comprehensive.py::TestOllamaProvider::test_ollama_generate FAILED [ 34%]\ntests/test_llm_client_comprehensive.py::TestOllamaProvider::test_ollama_connection_error FAILED [ 37%]\ntests/test_llm_client_comprehensive.py::TestOllamaProvider::test_ollama_server_error FAILED [ 40%]\ntests/test_llm_client_comprehensive.py::TestProviderSelection::test_primary_provider_selection FAILED [ 42%]\ntests/test_llm_client_comprehensive.py::TestProviderSelection::test_provider_availability FAILED [ 45%]\ntests/test_llm_client_comprehensive.py::TestProviderSelection::test_provider_fallback FAILED [ 48%]\ntests/test_llm_client_comprehensive.py::TestGenerationMethods::test_generate_with_request_object FAILED [ 51%]\ntests/test_llm_client_comprehensive.py::TestGenerationMethods::test_generate_with_parameters FAILED [ 54%]\ntests/test_llm_client_comprehensive.py::TestGenerationMethods::test_generate_with_context FAILED [ 57%]\ntests/test_llm_client_comprehensive.py::TestStreamingGeneration::test_stream_generate_openai FAILED [ 60%]\ntests/test_llm_client_comprehensive.py::TestStreamingGeneration::test_stream_generate_ollama FAILED [ 62%]\ntests/test_llm_client_comprehensive.py::TestErrorHandling::test_invalid_request FAILED [ 65%]\ntests/test_llm_client_comprehensive.py::TestErrorHandling::test_provider_unavailable FAILED [ 68%]\ntests/test_llm_client_comprehensive.py::TestErrorHandling::test_network_timeout FAILED [ 71%]\ntests/test_llm_client_comprehensive.py::TestErrorHandling::test_invalid_response_format FAILED [ 74%]\ntests/test_llm_client_comprehensive.py::TestPerformance::test_generation_performance FAILED [ 77%]\ntests/test_llm_client_comprehensive.py::TestPerformance::test_concurrent_generation FAILED [ 80%]\ntests/test_llm_client_comprehensive.py::TestPerformance::test_large_prompt_handling FAILED [ 82%]\ntests/test_llm_client_comprehensive.py::TestIntegration::test_memory_manager_integration FAILED [ 85%]\ntests/test_llm_client_comprehensive.py::TestIntegration::test_agent_integration PASSED [ 88%]\ntests/test_llm_client_comprehensive.py::TestIntegration::test_tool_manager_integration PASSED [ 91%]\ntests/test_llm_client_comprehensive.py::TestConfiguration::test_environment_variable_loading FAILED [ 94%]\ntests/test_llm_client_comprehensive.py::TestConfiguration::test_configuration_validation FAILED [ 97%]\ntests/test_llm_client_comprehensive.py::TestConfiguration::test_model_validation PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________ TestLLMClientCore.test_llm_client_initialization _______________\ntests/test_llm_client_comprehensive.py:27: in test_llm_client_initialization\n    assert hasattr(client, 'openai_client')\nE   AssertionError: assert False\nE    +  where False = hasattr(<llm_client.LLMClient object at 0x7efe090b9010>, 'openai_client')\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:29,048 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090ba120>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,048 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,048 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log call -------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090ba120>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n_______________ TestLLMClientCore.test_llm_client_configuration ________________\ntests/test_llm_client_comprehensive.py:39: in test_llm_client_configuration\n    assert client.openai_api_key == \"test_key\"\n           ^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMClient' object has no attribute 'openai_api_key'\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:29,084 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d5d950>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,084 - llm_client - INFO - LLM client initialized with primary provider: openai\n------------------------------ Captured log call -------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d5d950>: Failed to establish a new connection: [Errno 111] Connection refused'))\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: openai\n_________________ TestLLMClientCore.test_llm_client_providers __________________\ntests/test_llm_client_comprehensive.py:47: in test_llm_client_providers\n    assert \"openai\" in client.providers\nE   AssertionError: assert 'openai' in {'ollama': <llm_client.OllamaProvider object at 0x7efe08d5dd10>}\nE    +  where {'ollama': <llm_client.OllamaProvider object at 0x7efe08d5dd10>} = <llm_client.LLMClient object at 0x7efe08d5d6d0>.providers\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:29,090 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d5e0d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,090 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,090 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log call -------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d5e0d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n___________________ TestLLMRequest.test_llm_request_defaults ___________________\ntests/test_llm_client_comprehensive.py:73: in test_llm_request_defaults\n    assert request.max_tokens == 1000  # Default value\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AssertionError: assert 2000 == 1000\nE    +  where 2000 = LLMRequest(prompt='Test prompt', model=None, max_tokens=2000, temperature=0.7, system_message=None, functions=None, function_call=None).max_tokens\n__________________ TestLLMResponse.test_llm_response_defaults __________________\ntests/test_llm_client_comprehensive.py:109: in test_llm_response_defaults\n    response = LLMResponse(content=\"Test content\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   pydantic_core._pydantic_core.ValidationError: 2 validation errors for LLMResponse\nE   model\nE     Field required [type=missing, input_value={'content': 'Test content'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\nE   provider\nE     Field required [type=missing, input_value={'content': 'Test content'}, input_type=dict]\nE       For further information visit https://errors.pydantic.dev/2.11/v/missing\n___________________ TestOpenAIProvider.test_openai_generate ____________________\ntests/test_llm_client_comprehensive.py:141: in test_openai_generate\n    with patch.object(llm_client.openai_client.chat.completions, 'create', return_value=mock_response):\n                      ^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMClient' object has no attribute 'openai_client'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,109 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08dc7230>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,109 - llm_client - INFO - LLM client initialized with primary provider: openai\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08dc7230>: Failed to establish a new connection: [Errno 111] Connection refused'))\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: openai\n________________ TestOpenAIProvider.test_openai_error_handling _________________\ntests/test_llm_client_comprehensive.py:160: in test_openai_error_handling\n    with patch.object(llm_client.openai_client.chat.completions, 'create', side_effect=Exception(\"OpenAI API error\")):\n                      ^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMClient' object has no attribute 'openai_client'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,120 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08dc7230>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,120 - llm_client - INFO - LLM client initialized with primary provider: openai\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08dc7230>: Failed to establish a new connection: [Errno 111] Connection refused'))\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: openai\n_________________ TestOpenAIProvider.test_openai_rate_limiting _________________\ntests/test_llm_client_comprehensive.py:172: in test_openai_rate_limiting\n    with patch.object(llm_client.openai_client.chat.completions, 'create', side_effect=RateLimitError(\"Rate limit exceeded\", response=None, body=None)):\n                      ^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMClient' object has no attribute 'openai_client'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,130 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d4b2f0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,130 - llm_client - INFO - LLM client initialized with primary provider: openai\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d4b2f0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: openai\n___________________ TestOllamaProvider.test_ollama_generate ____________________\ntests/test_llm_client_comprehensive.py:206: in test_ollama_generate\n    with patch('aiohttp.ClientSession.post') as mock_post:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1481: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n/usr/lib/python3.13/pkgutil.py:513: in resolve_name\n    mod = importlib.import_module(modname)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/importlib/__init__.py:88: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1324: in _find_and_load_unlocked\n    ???\nE   ModuleNotFoundError: No module named 'aiohttp'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,136 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d37570>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,136 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d37570>: Failed to establish a new connection: [Errno 111] Connection refused'))\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n_______________ TestOllamaProvider.test_ollama_connection_error ________________\ntests/test_llm_client_comprehensive.py:227: in test_ollama_connection_error\n    with patch('aiohttp.ClientSession.post', side_effect=Exception(\"Connection error\")):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1481: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n/usr/lib/python3.13/pkgutil.py:513: in resolve_name\n    mod = importlib.import_module(modname)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/importlib/__init__.py:88: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1324: in _find_and_load_unlocked\n    ???\nE   ModuleNotFoundError: No module named 'aiohttp'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,185 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090789e0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,185 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090789e0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n_________________ TestOllamaProvider.test_ollama_server_error __________________\ntests/test_llm_client_comprehensive.py:236: in test_ollama_server_error\n    with patch('aiohttp.ClientSession.post') as mock_post:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1481: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n/usr/lib/python3.13/pkgutil.py:513: in resolve_name\n    mod = importlib.import_module(modname)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/importlib/__init__.py:88: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1324: in _find_and_load_unlocked\n    ???\nE   ModuleNotFoundError: No module named 'aiohttp'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,221 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe09078e20>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,221 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe09078e20>: Failed to establish a new connection: [Errno 111] Connection refused'))\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n____________ TestProviderSelection.test_primary_provider_selection _____________\ntests/test_llm_client_comprehensive.py:254: in test_primary_provider_selection\n    assert client.primary_provider == \"openai\"\nE   AssertionError: assert 'ollama' == 'openai'\nE     \nE     - openai\nE     + ollama\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:29,257 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090789e0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,257 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,257 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log call -------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090789e0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n_______________ TestProviderSelection.test_provider_availability _______________\ntests/test_llm_client_comprehensive.py:265: in test_provider_availability\n    assert client_with_key._is_provider_available(\"openai\") == True\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMClient' object has no attribute '_is_provider_available'\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:29,262 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe09079150>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,262 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,262 - llm_client - INFO - LLM client initialized with primary provider: ollama\n2025-09-09 11:48:29,267 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d36140>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,267 - llm_client - INFO - LLM client initialized with primary provider: openai\n------------------------------ Captured log call -------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe09079150>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d36140>: Failed to establish a new connection: [Errno 111] Connection refused'))\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: openai\n_________________ TestProviderSelection.test_provider_fallback _________________\ntests/test_llm_client_comprehensive.py:280: in test_provider_fallback\n    with patch.object(client, '_call_ollama') as mock_ollama:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <llm_client.LLMClient object at 0x7efe08d5f390> does not have the attribute '_call_ollama'\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:29,273 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d35f20>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,273 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,273 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log call -------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d35f20>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n___________ TestGenerationMethods.test_generate_with_request_object ____________\ntests/test_llm_client_comprehensive.py:305: in test_generate_with_request_object\n    with patch.object(llm_client, '_call_openai') as mock_openai:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <llm_client.LLMClient object at 0x7efe08d5f9d0> does not have the attribute '_call_openai'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,302 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d36360>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,302 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,302 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d36360>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n_____________ TestGenerationMethods.test_generate_with_parameters ______________\ntests/test_llm_client_comprehensive.py:327: in test_generate_with_parameters\n    with patch.object(llm_client, '_call_openai') as mock_openai:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <llm_client.LLMClient object at 0x7eff264e7b10> does not have the attribute '_call_openai'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,415 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff2638b8a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,415 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,415 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff2638b8a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n_______________ TestGenerationMethods.test_generate_with_context _______________\ntests/test_llm_client_comprehensive.py:348: in test_generate_with_context\n    with patch.object(llm_client, '_call_openai') as mock_openai:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <llm_client.LLMClient object at 0x7eff264e7250> does not have the attribute '_call_openai'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,445 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff34d8a690>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,445 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,445 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff34d8a690>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n_____________ TestStreamingGeneration.test_stream_generate_openai ______________\ntests/test_llm_client_comprehensive.py:386: in test_stream_generate_openai\n    with patch.object(llm_client.openai_client.chat.completions, 'create') as mock_create:\n                      ^^^^^^^^^^^^^^^^^^^^^^^^\nE   AttributeError: 'LLMClient' object has no attribute 'openai_client'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,475 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090787c0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,475 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,475 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090787c0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n_____________ TestStreamingGeneration.test_stream_generate_ollama ______________\ntests/test_llm_client_comprehensive.py:409: in test_stream_generate_ollama\n    with patch('aiohttp.ClientSession.post') as mock_post:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1481: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n/usr/lib/python3.13/pkgutil.py:513: in resolve_name\n    mod = importlib.import_module(modname)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/importlib/__init__.py:88: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1324: in _find_and_load_unlocked\n    ???\nE   ModuleNotFoundError: No module named 'aiohttp'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,481 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff2638b8a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,481 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,481 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff2638b8a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n____________________ TestErrorHandling.test_invalid_request ____________________\n/home/ubuntu/.local/lib/python3.13/site-packages/urllib3/connection.py:198: in _new_conn\n    sock = connection.create_connection(\n/home/ubuntu/.local/lib/python3.13/site-packages/urllib3/util/connection.py:85: in create_connection\n    raise err\n/home/ubuntu/.local/lib/python3.13/site-packages/urllib3/util/connection.py:73: in create_connection\n    sock.connect(sa)\nE   ConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n/home/ubuntu/.local/lib/python3.13/site-packages/urllib3/connectionpool.py:787: in urlopen\n    response = self._make_request(\n/home/ubuntu/.local/lib/python3.13/site-packages/urllib3/connectionpool.py:493: in _make_request\n    conn.request(\n/home/ubuntu/.local/lib/python3.13/site-packages/urllib3/connection.py:494: in request\n    self.endheaders()\n/usr/lib/python3.13/http/client.py:1333: in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n/usr/lib/python3.13/http/client.py:1093: in _send_output\n    self.send(msg)\n/usr/lib/python3.13/http/client.py:1037: in send\n    self.connect()\n/home/ubuntu/.local/lib/python3.13/site-packages/urllib3/connection.py:325: in connect\n    self.sock = self._new_conn()\n                ^^^^^^^^^^^^^^^^\n/home/ubuntu/.local/lib/python3.13/site-packages/urllib3/connection.py:213: in _new_conn\n    raise NewConnectionError(\nE   urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7efe08d35260>: Failed to establish a new connection: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n/home/ubuntu/.local/lib/python3.13/site-packages/requests/adapters.py:644: in send\n    resp = conn.urlopen(\n/home/ubuntu/.local/lib/python3.13/site-packages/urllib3/connectionpool.py:841: in urlopen\n    retries = retries.increment(\n/home/ubuntu/.local/lib/python3.13/site-packages/urllib3/util/retry.py:519: in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d35260>: Failed to establish a new connection: [Errno 111] Connection refused'))\n\nDuring handling of the above exception, another exception occurred:\ntests/test_llm_client_comprehensive.py:444: in test_invalid_request\n    await llm_client.generate(prompt=\"\")\nllm_client.py:394: in generate\n    return await provider.generate(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nllm_client.py:223: in generate\n    response = requests.post(\n/home/ubuntu/.local/lib/python3.13/site-packages/requests/api.py:115: in post\n    return request(\"post\", url, data=data, json=json, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/home/ubuntu/.local/lib/python3.13/site-packages/requests/api.py:59: in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/home/ubuntu/.local/lib/python3.13/site-packages/requests/sessions.py:589: in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/home/ubuntu/.local/lib/python3.13/site-packages/requests/sessions.py:703: in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/home/ubuntu/.local/lib/python3.13/site-packages/requests/adapters.py:677: in send\n    raise ConnectionError(e, request=request)\nE   requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d35260>: Failed to establish a new connection: [Errno 111] Connection refused'))\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,517 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff2638b8a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,517 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,517 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff2638b8a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:29,518 - llm_client - ERROR - Ollama API error: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d35260>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,518 - llm_client - ERROR - Primary provider ollama failed: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d35260>: Failed to establish a new connection: [Errno 111] Connection refused'))\n------------------------------ Captured log call -------------------------------\nERROR    llm_client:llm_client.py:250 Ollama API error: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d35260>: Failed to establish a new connection: [Errno 111] Connection refused'))\nERROR    llm_client:llm_client.py:396 Primary provider ollama failed: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d35260>: Failed to establish a new connection: [Errno 111] Connection refused'))\n_________________ TestErrorHandling.test_provider_unavailable __________________\ntests/test_llm_client_comprehensive.py:450: in test_provider_unavailable\n    with patch.object(llm_client, '_is_provider_available', return_value=False):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <llm_client.LLMClient object at 0x7efe0905b890> does not have the attribute '_is_provider_available'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,585 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff34d8a690>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,585 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,585 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff34d8a690>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n____________________ TestErrorHandling.test_network_timeout ____________________\ntests/test_llm_client_comprehensive.py:457: in test_network_timeout\n    with patch.object(llm_client, '_call_openai', side_effect=asyncio.TimeoutError(\"Request timeout\")):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <llm_client.LLMClient object at 0x7efe0905bed0> does not have the attribute '_call_openai'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,616 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090787c0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,616 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,616 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090787c0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n________________ TestErrorHandling.test_invalid_response_format ________________\ntests/test_llm_client_comprehensive.py:464: in test_invalid_response_format\n    with patch.object(llm_client, '_call_openai') as mock_openai:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <llm_client.LLMClient object at 0x7eff34b32210> does not have the attribute '_call_openai'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,646 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff34d8a8b0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,646 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,647 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff34d8a8b0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n_________________ TestPerformance.test_generation_performance __________________\ntests/test_llm_client_comprehensive.py:484: in test_generation_performance\n    with patch.object(llm_client, '_call_openai') as mock_openai:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <llm_client.LLMClient object at 0x7eff34b31e50> does not have the attribute '_call_openai'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,677 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090787c0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,677 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,677 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090787c0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n__________________ TestPerformance.test_concurrent_generation __________________\ntests/test_llm_client_comprehensive.py:501: in test_concurrent_generation\n    with patch.object(llm_client, '_call_openai') as mock_openai:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <llm_client.LLMClient object at 0x7efe0905bed0> does not have the attribute '_call_openai'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,708 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff34d8a690>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,708 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,708 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff34d8a690>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n__________________ TestPerformance.test_large_prompt_handling __________________\ntests/test_llm_client_comprehensive.py:525: in test_large_prompt_handling\n    with patch.object(llm_client, '_call_openai') as mock_openai:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1497: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n/usr/lib/python3.13/unittest/mock.py:1467: in get_original\n    raise AttributeError(\nE   AttributeError: <llm_client.LLMClient object at 0x7efe0905b890> does not have the attribute '_call_openai'\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,738 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff2638b8a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,739 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,739 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7eff2638b8a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n_______________ TestIntegration.test_memory_manager_integration ________________\ntests/test_llm_client_comprehensive.py:569: in test_memory_manager_integration\n    assert \"Context from memory\" in context\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nE   TypeError: argument of type 'coroutine' is not iterable\n---------------------------- Captured stderr setup -----------------------------\n2025-09-09 11:48:29,769 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090788d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:29,769 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:29,769 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log setup ------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe090788d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:29,843 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n2025-09-09 11:48:29,843 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n2025-09-09 11:48:30,138 - memory_manager - INFO - Memory manager initialized with persist directory: memory_db\n------------------------------ Captured log call -------------------------------\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:219 Use pytorch device_name: cpu\nINFO     sentence_transformers.SentenceTransformer:SentenceTransformer.py:227 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\nINFO     memory_manager:memory_manager.py:107 Memory manager initialized with persist directory: memory_db\n_____________ TestConfiguration.test_environment_variable_loading ______________\ntests/test_llm_client_comprehensive.py:622: in test_environment_variable_loading\n    assert hasattr(client, 'openai_api_key')\nE   AssertionError: assert False\nE    +  where False = hasattr(<llm_client.LLMClient object at 0x7efe08aede50>, 'openai_api_key')\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:30,148 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe09078e20>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:30,148 - llm_client - WARNING - Primary provider openai not available, using ollama\n2025-09-09 11:48:30,148 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log call -------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe09078e20>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider openai not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n_______________ TestConfiguration.test_configuration_validation ________________\ntests/test_llm_client_comprehensive.py:628: in test_configuration_validation\n    with pytest.raises(ValueError):\n         ^^^^^^^^^^^^^^^^^^^^^^^^^\nE   Failed: DID NOT RAISE <class 'ValueError'>\n----------------------------- Captured stderr call -----------------------------\n2025-09-09 11:48:30,153 - llm_client - WARNING - Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe09078e20>: Failed to establish a new connection: [Errno 111] Connection refused'))\n2025-09-09 11:48:30,153 - llm_client - WARNING - Primary provider invalid_provider not available, using ollama\n2025-09-09 11:48:30,153 - llm_client - INFO - LLM client initialized with primary provider: ollama\n------------------------------ Captured log call -------------------------------\nWARNING  llm_client:llm_client.py:201 Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe09078e20>: Failed to establish a new connection: [Errno 111] Connection refused'))\nWARNING  llm_client:llm_client.py:348 Primary provider invalid_provider not available, using ollama\nINFO     llm_client:llm_client.py:352 LLM client initialized with primary provider: ollama\n=============================== warnings summary ===============================\n../home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21\n  /home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============================= slowest 10 durations =============================\n0.37s call     tests/test_llm_client_comprehensive.py::TestIntegration::test_memory_manager_integration\n0.02s call     tests/test_llm_client_comprehensive.py::TestLLMClientCore::test_llm_client_configuration\n0.01s call     tests/test_llm_client_comprehensive.py::TestProviderSelection::test_provider_availability\n0.01s setup    tests/test_llm_client_comprehensive.py::TestOpenAIProvider::test_openai_generate\n0.01s setup    tests/test_llm_client_comprehensive.py::TestOpenAIProvider::test_openai_error_handling\n0.01s setup    tests/test_llm_client_comprehensive.py::TestOpenAIProvider::test_openai_rate_limiting\n0.00s call     tests/test_llm_client_comprehensive.py::TestLLMClientCore::test_llm_client_initialization\n0.00s setup    tests/test_llm_client_comprehensive.py::TestErrorHandling::test_provider_unavailable\n0.00s setup    tests/test_llm_client_comprehensive.py::TestErrorHandling::test_network_timeout\n0.00s setup    tests/test_llm_client_comprehensive.py::TestPerformance::test_large_prompt_handling\n=========================== short test summary info ============================\nFAILED tests/test_llm_client_comprehensive.py::TestLLMClientCore::test_llm_client_initialization - AssertionError: assert False\n +  where False = hasattr(<llm_client.LLMClient object at 0x7efe090b9010>, 'openai_client')\nFAILED tests/test_llm_client_comprehensive.py::TestLLMClientCore::test_llm_client_configuration - AttributeError: 'LLMClient' object has no attribute 'openai_api_key'\nFAILED tests/test_llm_client_comprehensive.py::TestLLMClientCore::test_llm_client_providers - AssertionError: assert 'openai' in {'ollama': <llm_client.OllamaProvider object at 0x7efe08d5dd10>}\n +  where {'ollama': <llm_client.OllamaProvider object at 0x7efe08d5dd10>} = <llm_client.LLMClient object at 0x7efe08d5d6d0>.providers\nFAILED tests/test_llm_client_comprehensive.py::TestLLMRequest::test_llm_request_defaults - AssertionError: assert 2000 == 1000\n +  where 2000 = LLMRequest(prompt='Test prompt', model=None, max_tokens=2000, temperature=0.7, system_message=None, functions=None, function_call=None).max_tokens\nFAILED tests/test_llm_client_comprehensive.py::TestLLMResponse::test_llm_response_defaults - pydantic_core._pydantic_core.ValidationError: 2 validation errors for LLMResponse\nmodel\n  Field required [type=missing, input_value={'content': 'Test content'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nprovider\n  Field required [type=missing, input_value={'content': 'Test content'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nFAILED tests/test_llm_client_comprehensive.py::TestOpenAIProvider::test_openai_generate - AttributeError: 'LLMClient' object has no attribute 'openai_client'\nFAILED tests/test_llm_client_comprehensive.py::TestOpenAIProvider::test_openai_error_handling - AttributeError: 'LLMClient' object has no attribute 'openai_client'\nFAILED tests/test_llm_client_comprehensive.py::TestOpenAIProvider::test_openai_rate_limiting - AttributeError: 'LLMClient' object has no attribute 'openai_client'\nFAILED tests/test_llm_client_comprehensive.py::TestOllamaProvider::test_ollama_generate - ModuleNotFoundError: No module named 'aiohttp'\nFAILED tests/test_llm_client_comprehensive.py::TestOllamaProvider::test_ollama_connection_error - ModuleNotFoundError: No module named 'aiohttp'\nFAILED tests/test_llm_client_comprehensive.py::TestOllamaProvider::test_ollama_server_error - ModuleNotFoundError: No module named 'aiohttp'\nFAILED tests/test_llm_client_comprehensive.py::TestProviderSelection::test_primary_provider_selection - AssertionError: assert 'ollama' == 'openai'\n  \n  - openai\n  + ollama\nFAILED tests/test_llm_client_comprehensive.py::TestProviderSelection::test_provider_availability - AttributeError: 'LLMClient' object has no attribute '_is_provider_available'\nFAILED tests/test_llm_client_comprehensive.py::TestProviderSelection::test_provider_fallback - AttributeError: <llm_client.LLMClient object at 0x7efe08d5f390> does not have the attribute '_call_ollama'\nFAILED tests/test_llm_client_comprehensive.py::TestGenerationMethods::test_generate_with_request_object - AttributeError: <llm_client.LLMClient object at 0x7efe08d5f9d0> does not have the attribute '_call_openai'\nFAILED tests/test_llm_client_comprehensive.py::TestGenerationMethods::test_generate_with_parameters - AttributeError: <llm_client.LLMClient object at 0x7eff264e7b10> does not have the attribute '_call_openai'\nFAILED tests/test_llm_client_comprehensive.py::TestGenerationMethods::test_generate_with_context - AttributeError: <llm_client.LLMClient object at 0x7eff264e7250> does not have the attribute '_call_openai'\nFAILED tests/test_llm_client_comprehensive.py::TestStreamingGeneration::test_stream_generate_openai - AttributeError: 'LLMClient' object has no attribute 'openai_client'\nFAILED tests/test_llm_client_comprehensive.py::TestStreamingGeneration::test_stream_generate_ollama - ModuleNotFoundError: No module named 'aiohttp'\nFAILED tests/test_llm_client_comprehensive.py::TestErrorHandling::test_invalid_request - requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efe08d35260>: Failed to establish a new connection: [Errno 111] Connection refused'))\nFAILED tests/test_llm_client_comprehensive.py::TestErrorHandling::test_provider_unavailable - AttributeError: <llm_client.LLMClient object at 0x7efe0905b890> does not have the attribute '_is_provider_available'\nFAILED tests/test_llm_client_comprehensive.py::TestErrorHandling::test_network_timeout - AttributeError: <llm_client.LLMClient object at 0x7efe0905bed0> does not have the attribute '_call_openai'\nFAILED tests/test_llm_client_comprehensive.py::TestErrorHandling::test_invalid_response_format - AttributeError: <llm_client.LLMClient object at 0x7eff34b32210> does not have the attribute '_call_openai'\nFAILED tests/test_llm_client_comprehensive.py::TestPerformance::test_generation_performance - AttributeError: <llm_client.LLMClient object at 0x7eff34b31e50> does not have the attribute '_call_openai'\nFAILED tests/test_llm_client_comprehensive.py::TestPerformance::test_concurrent_generation - AttributeError: <llm_client.LLMClient object at 0x7efe0905bed0> does not have the attribute '_call_openai'\nFAILED tests/test_llm_client_comprehensive.py::TestPerformance::test_large_prompt_handling - AttributeError: <llm_client.LLMClient object at 0x7efe0905b890> does not have the attribute '_call_openai'\nFAILED tests/test_llm_client_comprehensive.py::TestIntegration::test_memory_manager_integration - TypeError: argument of type 'coroutine' is not iterable\nFAILED tests/test_llm_client_comprehensive.py::TestConfiguration::test_environment_variable_loading - AssertionError: assert False\n +  where False = hasattr(<llm_client.LLMClient object at 0x7efe08aede50>, 'openai_api_key')\nFAILED tests/test_llm_client_comprehensive.py::TestConfiguration::test_configuration_validation - Failed: DID NOT RAISE <class 'ValueError'>\n=================== 29 failed, 6 passed, 1 warning in 1.16s ====================\n",
      "stderr": "/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/unraisableexception.py:33: RuntimeWarning: coroutine 'MemoryManager.get_context_for_generation' was never awaited\n  gc.collect()\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
    },
    {
      "name": "Tool Manager Comprehensive",
      "file": "tests/test_tool_manager_comprehensive.py",
      "category": "unit",
      "status": "FAILED",
      "duration": 4.154501438140869,
      "passed": 0,
      "failed": 0,
      "skipped": 0,
      "errors": 0,
      "total": 0,
      "returncode": 2,
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.13.3, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /workspace\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, asyncio-1.1.0, mock-3.15.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 0 items / 1 error\n\n==================================== ERRORS ====================================\n__________ ERROR collecting tests/test_tool_manager_comprehensive.py ___________\nImportError while importing test module '/workspace/tests/test_tool_manager_comprehensive.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/python.py:498: in importtestmodule\n    mod = import_path(\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n/usr/lib/python3.13/importlib/__init__.py:88: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/assertion/rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests/test_tool_manager_comprehensive.py:15: in <module>\n    from tool_manager import (\nE   ImportError: cannot import name 'ToolExecutionError' from 'tool_manager' (/workspace/tool_manager.py)\n=============================== warnings summary ===============================\n../home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21\n  /home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nERROR tests/test_tool_manager_comprehensive.py\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n========================= 1 warning, 1 error in 0.13s ==========================\n",
      "stderr": ""
    },
    {
      "name": "Agent Manager Comprehensive",
      "file": "tests/test_agent_manager_comprehensive.py",
      "category": "unit",
      "status": "FAILED",
      "duration": 4.229942798614502,
      "passed": 0,
      "failed": 0,
      "skipped": 0,
      "errors": 0,
      "total": 0,
      "returncode": 2,
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.13.3, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /workspace\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, asyncio-1.1.0, mock-3.15.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 0 items / 1 error\n\n==================================== ERRORS ====================================\n__________ ERROR collecting tests/test_agent_manager_comprehensive.py __________\nImportError while importing test module '/workspace/tests/test_agent_manager_comprehensive.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/python.py:498: in importtestmodule\n    mod = import_path(\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n/usr/lib/python3.13/importlib/__init__.py:88: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/assertion/rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests/test_agent_manager_comprehensive.py:15: in <module>\n    from agent_manager import (\nE   ImportError: cannot import name 'Agent' from 'agent_manager' (/workspace/agent_manager.py)\n=============================== warnings summary ===============================\n../home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21\n  /home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nERROR tests/test_agent_manager_comprehensive.py\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n========================= 1 warning, 1 error in 0.14s ==========================\n",
      "stderr": ""
    },
    {
      "name": "System Integration Comprehensive",
      "file": "tests/test_system_integration_comprehensive.py",
      "category": "integration",
      "status": "FAILED",
      "duration": 4.530365943908691,
      "passed": 0,
      "failed": 0,
      "skipped": 0,
      "errors": 0,
      "total": 0,
      "returncode": 2,
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.13.3, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /workspace\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, asyncio-1.1.0, mock-3.15.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 0 items / 1 error\n\n==================================== ERRORS ====================================\n_______ ERROR collecting tests/test_system_integration_comprehensive.py ________\nImportError while importing test module '/workspace/tests/test_system_integration_comprehensive.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/python.py:498: in importtestmodule\n    mod = import_path(\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/pathlib.py:587: in import_path\n    importlib.import_module(module_name)\n/usr/lib/python3.13/importlib/__init__.py:88: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n<frozen importlib._bootstrap>:1387: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1360: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:935: in _load_unlocked\n    ???\n/home/ubuntu/.local/lib/python3.13/site-packages/_pytest/assertion/rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests/test_system_integration_comprehensive.py:20: in <module>\n    from agent_manager import AgentManager, Agent, AgentTask, TaskPriority\nE   ImportError: cannot import name 'Agent' from 'agent_manager' (/workspace/agent_manager.py)\n=============================== warnings summary ===============================\n../home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21\n  /home/ubuntu/.local/lib/python3.13/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nERROR tests/test_system_integration_comprehensive.py\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n========================= 1 warning, 1 error in 0.13s ==========================\n",
      "stderr": ""
    }
  ],
  "summary": {
    "total_tests": 173,
    "passed": 85,
    "failed": 88,
    "skipped": 0,
    "errors": 0,
    "success_rate": 49.13294797687861,
    "total_duration": 61.06848120689392,
    "test_suites": 10
  },
  "recommendations": [
    {
      "priority": "critical",
      "category": "reliability",
      "issue": "Low Success Rate",
      "solution": "Critical issues need immediate attention. Review and fix all failing tests.",
      "impact": "functionality"
    },
    {
      "priority": "high",
      "category": "testing",
      "issue": "Failed Test Suite: Core Functionality",
      "solution": "Review and fix issues in tests/test_core_functionality.py. Check error messages for specific problems.",
      "impact": "testing"
    },
    {
      "priority": "high",
      "category": "testing",
      "issue": "Failed Test Suite: Simple Tests",
      "solution": "Review and fix issues in tests/test_simple.py. Check error messages for specific problems.",
      "impact": "testing"
    },
    {
      "priority": "high",
      "category": "testing",
      "issue": "Failed Test Suite: GUI Comprehensive",
      "solution": "Review and fix issues in tests/test_gui_comprehensive.py. Check error messages for specific problems.",
      "impact": "testing"
    },
    {
      "priority": "high",
      "category": "testing",
      "issue": "Failed Test Suite: Document Ingestor Comprehensive",
      "solution": "Review and fix issues in tests/test_document_ingestor_comprehensive.py. Check error messages for specific problems.",
      "impact": "testing"
    },
    {
      "priority": "high",
      "category": "testing",
      "issue": "Failed Test Suite: Memory Manager Comprehensive",
      "solution": "Review and fix issues in tests/test_memory_manager_comprehensive.py. Check error messages for specific problems.",
      "impact": "testing"
    },
    {
      "priority": "high",
      "category": "testing",
      "issue": "Failed Test Suite: LLM Client Comprehensive",
      "solution": "Review and fix issues in tests/test_llm_client_comprehensive.py. Check error messages for specific problems.",
      "impact": "testing"
    },
    {
      "priority": "high",
      "category": "testing",
      "issue": "Failed Test Suite: Tool Manager Comprehensive",
      "solution": "Review and fix issues in tests/test_tool_manager_comprehensive.py. Check error messages for specific problems.",
      "impact": "testing"
    },
    {
      "priority": "high",
      "category": "testing",
      "issue": "Failed Test Suite: Agent Manager Comprehensive",
      "solution": "Review and fix issues in tests/test_agent_manager_comprehensive.py. Check error messages for specific problems.",
      "impact": "testing"
    },
    {
      "priority": "high",
      "category": "testing",
      "issue": "Failed Test Suite: System Integration Comprehensive",
      "solution": "Review and fix issues in tests/test_system_integration_comprehensive.py. Check error messages for specific problems.",
      "impact": "testing"
    },
    {
      "priority": "medium",
      "category": "testing",
      "issue": "Missing Test Coverage: book_workflow, error_handling, performance",
      "solution": "Add comprehensive tests for missing features.",
      "impact": "quality"
    },
    {
      "priority": "low",
      "category": "documentation",
      "issue": "Test Documentation",
      "solution": "Add comprehensive test documentation and examples.",
      "impact": "maintainability"
    },
    {
      "priority": "medium",
      "category": "automation",
      "issue": "Continuous Integration",
      "solution": "Set up automated testing pipeline for continuous validation.",
      "impact": "development"
    },
    {
      "priority": "low",
      "category": "monitoring",
      "issue": "Test Monitoring",
      "solution": "Add test result monitoring and alerting for failures.",
      "impact": "reliability"
    }
  ],
  "performance_metrics": {
    "total_duration": 61.06848120689392,
    "average_duration_per_suite": 6.106848120689392,
    "slowest_suite": "Memory Manager Comprehensive",
    "fastest_suite": "Tool Manager Comprehensive",
    "slow_test_count": 0,
    "performance_categories": {
      "excellent": 5,
      "good": 5,
      "acceptable": 0,
      "slow": 0,
      "very_slow": 0
    }
  },
  "coverage_analysis": {
    "total_modules_tested": 8,
    "modules_covered": [
      "memory_manager",
      "llm_client",
      "tool_manager",
      "agent_manager",
      "document_ingestor",
      "book_workflow",
      "gui",
      "cli"
    ],
    "modules_missing": [],
    "test_categories": {
      "unit_tests": 0,
      "integration_tests": 0,
      "system_tests": 0,
      "performance_tests": 0
    },
    "feature_coverage": {
      "core_functionality": true,
      "memory_management": true,
      "llm_integration": true,
      "tool_management": true,
      "agent_coordination": true,
      "document_processing": true,
      "gui_functionality": true,
      "book_workflow": false,
      "error_handling": false,
      "performance": false
    }
  }
}